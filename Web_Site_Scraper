#!/usr/bin/env python
# coding: utf-8

# **Basic Web Scraping with BeautifulSoup:** - Hacker News Jop Postings Jan 2023\
# **Notes:**

# Loading required libraries:

# In[73]:


import requests
from bs4 import BeautifulSoup #for parsing the data pulled from a html source
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np


# In[97]:


def main():
    # web page address for the data we want to pull
    url_jan23="https://news.ycombinator.com/item?id=34219335"
    raw_data = requests.get(url_jan23)
    
    soup= BeautifulSoup(raw_data.content,"html.parser")
    
    jan23_elements = soup.find_all(class_="ind", indent="0")     # class is a reserved word in Python so to avoid syntax error, we can use class keyword like 'class_' in BeautifulSoup
    jan23_comments = [e.find_next(class_="comment") for e in jan23_elements] # find next gives us only the first match and we need to do this through all the elements to get the comments separetely so we save it as list with for loop
    jan23_age = [e.find_next(class_= "age") for e in jan23_elements]


    keywords = ["python", "sql", "powerbi", "tableau", "r"]
    table_df = pd.DataFrame(columns=["remote","onsite"], index=["python","sql","powerbi","tableau","r"], data=0)
  
    
    # print(f"Scraping : {url}")
   # print("-----------------------------------------")
    #print(raw_data)
  
   # print(raw_data.content)
    print(f" # of comments: {len(jan23_comments)}")
    print(f" # of elements: {len(jan23_age)}")
    # print("-----------------------------------------")
    
    
    for com in jan23_comments:
        com_text= com.get_text().lower()
        words = com_text.split(" ") # split the comment text by space and created array of words
        words= {w.strip(".,:/@;!)(") for w in words} # strip all the words from unnecessary sings as a set so there will be no doublicate words
        #age_text = age.get_text() # getting the date info of the post
        
        #looking for how requşrements change by the type of workin - Remote/Onsite
        if "remote" in com_text:
            for k in keywords:
                if k in words:
                    table_df.at[k,'remote'] +=1
        if 'onsite' in com_text:
            for k in keywords:
                if k in words:
                    table_df.at[k,'onsite'] +=1
    print(table_df)
          
    
        #print("----")
        #print(age)
        #print("----")
        #print(words)
        #print("-----------------------------------------")
        

       
            
        
# This allows you to execute code when the file runs as a Script, but not when It’s imported as a Module
if __name__ == "__main__":
    main()

